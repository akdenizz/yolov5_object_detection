{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"yolov5_training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# You can look into this [medium blog](https://medium.com/move-on-ai/yolov5-object-detection-with-your-own-dataset-6e3823a8f66b) for more detailed info about yolov5 object detection"],"metadata":{"id":"Cmpzc7-msxdO"}},{"cell_type":"code","metadata":{"id":"R35oYVMqWUyh"},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create a folder that you will work on"],"metadata":{"id":"FmwT2Npbqf1F"}},{"cell_type":"code","metadata":{"id":"49gZ9wNWW4Sy"},"source":["cd /content/drive/MyDrive/yolov5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Setup\n","\n","Clone repo, install dependencies and check PyTorch and GPU."],"metadata":{"id":"TNOs3ub1sIMs"}},{"cell_type":"code","metadata":{"id":"IOo33IBdXMY4"},"source":["!git clone https://github.com/ultralytics/yolov5\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oZIKVjELji5e"},"source":["cd yolov5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1r0NkX-fjmxe"},"source":["!pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6DKv_VMnXsc4"},"source":["import torch\n","print('Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PoLcC5V9GH7H"},"source":["pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DBUY9OS9nl8Y"},"source":["#--> Before training, change data.yaml and yolov5l.yaml files\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"50vz6dLCFsV7"},"source":["%cat ./data/data.yaml"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J9UQiMJQFtLw"},"source":["%cat ./models/yolov5l.yaml"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lt6pGmevw4k8"},"source":["%cat ./data/hyps/hyp.scratch.yaml"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l0cM43wbet-f"},"source":["import os\n","os.chdir('/content/drive/MyDrive/yolov5_speed/yolov5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uBfHzLi0fdQz"},"source":["pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Train\n","\n","\n","Train a YOLOv5s model on the custom dataset with `--data data.yaml` that you will create, starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`.\n","\n","- **Pretrained [Models](https://github.com/ultralytics/yolov5/tree/master/models)** are downloaded\n","automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases)\n","- **[Datasets](https://github.com/ultralytics/yolov5/tree/master/data)** available for autodownload include: [COCO](https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml), [COCO128](https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml), [VOC](https://github.com/ultralytics/yolov5/blob/master/data/VOC.yaml), [Argoverse](https://github.com/ultralytics/yolov5/blob/master/data/Argoverse.yaml), [VisDrone](https://github.com/ultralytics/yolov5/blob/master/data/VisDrone.yaml), [GlobalWheat](https://github.com/ultralytics/yolov5/blob/master/data/GlobalWheat2020.yaml), [xView](https://github.com/ultralytics/yolov5/blob/master/data/xView.yaml), [Objects365](https://github.com/ultralytics/yolov5/blob/master/data/Objects365.yaml), [SKU-110K](https://github.com/ultralytics/yolov5/blob/master/data/SKU-110K.yaml).\n","- **Training Results** are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n","<br><br>\n"],"metadata":{"id":"dRh0qtwhsWJ0"}},{"cell_type":"markdown","source":["You can visualize with wandb like tensorboard"],"metadata":{"id":"uJ85yP4Jth4v"}},{"cell_type":"code","metadata":{"id":"4vW4OrwGRwBn"},"source":["!pip install wandb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ybf9GbAuStR"},"source":["!wandb login"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BaGbx4hke3dm"},"source":["%%time\n","%cd /content/drive/MyDrive/yolov5/yolov5\n","!python train.py --imgsz 640 --batch 16 --epochs 300 --data data/data.yaml --cfg models/yolov5l.yaml --weights weights/yolov5l.pt  --name result  --cache --device 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Inference\n","\n","`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n","\n","```shell\n","python detect.py --source 0  # webcam\n","                          img.jpg  # image \n","                          vid.mp4  # video\n","                          path/  # directory\n","                          path/*.jpg  # glob\n","                          'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n","                          'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n","```"],"metadata":{"id":"IPOtOUVptpsW"}},{"cell_type":"code","metadata":{"id":"P4KsTQ1KYiuz"},"source":["%cd  /content/drive/MyDrive/yolov5/yolov5\n","\n","!python detect.py --weights ./runs/train/result/weights/best.pt   --source 0 --conf-thres 0.6"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can export your model in any format that you want "],"metadata":{"id":"6dCK5Ce-rBT7"}},{"cell_type":"code","metadata":{"id":"2m76Ck1FZvfY"},"source":["!python ./export.py --weights ./runs/train/result/weights/best.pt --include onnx "],"execution_count":null,"outputs":[]}]}